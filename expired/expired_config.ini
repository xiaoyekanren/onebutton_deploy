[dwf]
# add hosts ssh's information,use,split
hosts=192.168.130.18
localuser=fit
localuser_passwd=601tif
sudouser=fit
sudouser_passwd=601tif
# config for dwf
dwf_url=https://cloud.tsinghua.edu.cn/f/4849cc5125b64cd59056/?dl=1
# config for
jdk_install_dir="/opt/jdk1.8.0_181"
maven_install_dir="/opt/maven-3.6.1"
node_install_dir="/opt/node-v10.16.0"
tomcat_install_dir="/opt/apache-tomcat"
dwf_install_dir="/opt/dwf3.0-deploy"


[storm]
# user,host for storm,use ',' to to separate
hosts=192.168.130.4,192.168.130.5,192.168.130.6
localuser=zzm
localuser_passwd=123456
#sudouser for storm
sudouser=zzm
sudouser_passwd=123456
#file for storm
storm_local_file=Tools\apache-storm-1.2.3.tar.gz
storm_folder=apache-storm-1.2.3
#config for storm,use ',' to separate nimbus_seeds and zookeeper_hosts
zookeeper_hosts=192.168.130.5
nimbus_host=192.168.130.4
nimbus_seeds=192.168.130.4,192.168.130.5,192.168.130.6
#    if storm_data without permission,must set sudouser
storm_data=/data/storm_data
#    number of supervisor.slots.ports,default is 4
supervisor_slots_ports_num=4


[deploy_cloudwise]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.7,192.168.130.11,192.168.130.12,192.168.130.13,192.168.130.14,192.168.130.15,192.168.130.17,192.168.130.18,192.168.130.19,192.168.130.20,192.168.130.21
localuser=root
localuser_passwd=root106A
#sudouser
sudouser=root
sudouser_passwd=root106A
#file,folder,path
local_file=Tools\OSAgent_Linux_2.1.2.zip
software_folder=OSAgent_Linux_2.1.2
install_path=/var/cloudwise
#-------------------------
#config
licensekey=J45Engw88NeHUZ4Q7qNsK8L47FTH**QvgW113IEnsNaBNMR5zZ**oj/g!!!!
received_hosts=http://101.6.15.214:15081


#Not supported below
[elasticsearch]
warning=!!must modify Config\elasticsearch.yml,add discovery.zen.ping.unicast.hosts is equal the env.hosts
elasticsearch_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\elasticsearch-6.6.1.tar.gz
elasticsearch_folder=elasticsearch-6.6.1
elasticsearch_data=/data/elasticsearch/data
elasticsearch_log=/data/elasticsearch/logs
[hbase]
hbase_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\hbase-2.1.3-bin.tar.gz
hbase_folder=hbase-2.1.3
hbase_rootdir=hdfs://172.16.244.5:9000/hbase
zoo_data=/data/zookeeper-data
zoo_user=ubuntu
zoo_user_pwd=Dwf12345
zoo_host=172.16.244.9
zoo_cfg_path=/home/ubuntu/zookeeper-3.4.13/conf/zoo.cfg
zookeeper_ip=172.16.244.9,172.16.244.14,172.16.244.13
[hive]
hive_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\apache-hive-2.3.4-bin.tar.gz
hive_host=172.16.244.27
hive_user=ubuntu
hive_folder=apache-hive-2.3.4-bin
mysql_connector_java_path=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\mysql-connector-java-8.0.15.jar
mysql_host=172.16.244.27
mysql_port=3306
mysql_hive_user=hive
mysql_root_pwd=123456
mysql_hive_user_pwd=hive
hadoop_path=/home/ubuntu/hadoop-2.7.7
hadoop_user=ubuntu
hadoop_password=Dwf12345
[hbase2]
hbase_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\flink-1.7.2-bin-hadoop27-scala_2.11.tgz
hbase_folder=flink-1.7.2