[common]
# yes or no
use_the_same_hostname=no
#
hosts=192.168.10.62,192.168.10.64
localuser=zzm
localuser_passwd=123456
sudouser=ubuntu
sudouser_passwd=123456


[jdk]
#-------------------------
# add hosts ssh's information,use , split
hosts=172.16.2.2,172.16.2.3,172.16.2.4,172.16.2.5,172.16.2.6,172.16.2.7,172.16.2.8,172.16.2.9,172.16.2.10,172.16.2.11,172.16.2.12,172.16.2.13,172.16.2.14,172.16.2.15,172.16.2.16,172.16.2.17,172.16.2.18,172.16.2.19,172.16.2.20,172.16.2.21,172.16.2.22,172.16.2.23,172.16.2.24,172.16.2.25,172.16.2.26,172.16.2.27,172.16.2.28,172.16.2.29,172.16.2.30,172.16.2.31,172.16.2.32,172.16.2.33
localuser=cluster
localuser_passwd=iotdb2021
#sudouser
sudouser=root
sudouser_passwd=IoTDB2021
#file,folder,path
local_file=Tools\jdk-11.0.14_linux-x64_bin.tar.gz
software_folder=jdk-11.0.14
install_path=/usr/local
#-------------------------
#config for jdk
# install for alone or public?
install_for=alone


[iotdb-cluster]
#-------------------------
# host,user
# add hosts ssh's info, use ',' split
hosts=11.101.17.14,11.101.17.15,11.101.17.16,11.101.17.17,11.101.17.18
localuser=zzm
localuser_passwd=123456
# sudouser
sudouser=root
sudouser_passwd=qh123456
# file,folder,path
local_file=Tools\apache-iotdb-1.0.1-SNAPSHOT-all-bin.zip
software_folder=apache-iotdb-1.0.1-SNAPSHOT-all-bin
install_path=/data1/zzm/rel_101
# cluster info
first_confignode=11.101.17.14
config_node=11.101.17.14
data_node=11.101.17.14,11.101.17.15,11.101.17.16,11.101.17.17,11.101.17.18
[iotdb-cluster-config]
# iotdb-common.properties
;config_node_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;schema_replication_factor=1
;schema_region_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;data_replication_factor=1
;data_region_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;schema_region_ratis_snapshot_trigger_threshold=1000


[keyfree_login]
hosts=172.16.2.2,172.16.2.3,172.16.2.4,172.16.2.5,172.16.2.6,172.16.2.7,172.16.2.8,172.16.2.9,172.16.2.10,172.16.2.11,172.16.2.12,172.16.2.13,172.16.2.14,172.16.2.15,172.16.2.16,172.16.2.17,172.16.2.18,172.16.2.19,172.16.2.20,172.16.2.21,172.16.2.22,172.16.2.23,172.16.2.24,172.16.2.25,172.16.2.26,172.16.2.27,172.16.2.28,172.16.2.29,172.16.2.30,172.16.2.31,172.16.2.32,172.16.2.33
localuser=root
localuser_passwd=IoTDB2021


[hostname_to_host]
hosts=192.168.130.171,192.168.130.144,192.168.130.145
#
sudouser=ubuntu
sudouser_passwd=123456
#ip and hostname must one-to-one
ip=192.168.130.171,192.168.130.144,192.168.130.145
hostname=slave1,slave2,slave3



[maven]
# add hosts ssh's information,use,split
hosts=192.168.10.71,192.168.10.72,192.168.10.73,192.168.10.74,192.168.10.75,192.168.10.76
localuser=fit
localuser_passwd=fit106
# If you need install jdk for global,then add the following information.
# otherwise, don't care.
sudouser=fit
sudouser_passwd=fit106
# add path for jdk
user_home=/home/fit
mvn_local_file=Tools\apache-maven-3.8.5-bin.tar.gz
mvn_folder=apache-maven-3.8.5


[dwf]
# add hosts ssh's information,use,split
hosts=192.168.130.18
localuser=fit
localuser_passwd=601tif
sudouser=fit
sudouser_passwd=601tif
# config for dwf
dwf_url=https://cloud.tsinghua.edu.cn/f/4849cc5125b64cd59056/?dl=1
# config for
jdk_install_dir="/opt/jdk1.8.0_181"
maven_install_dir="/opt/maven-3.6.1"
node_install_dir="/opt/node-v10.16.0"
tomcat_install_dir="/opt/apache-tomcat"
dwf_install_dir="/opt/dwf3.0-deploy"


[hadoop]
#-------------------------
# user,host for hadoop,use ',' to to separate
hosts=192.168.130.171,192.168.130.144,192.168.130.145
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\hadoop-2.8.5.tar.gz
software_folder=hadoop-2.8.5
install_path=/home/ubuntu
#-------------------------
#config for hadoop
master_ip=192.168.130.171
slaves=192.168.130.171,192.168.130.144,192.168.130.145
#    data_folder can have multiple directory,use ',' to to separate data_folder and slaves
data_folder=/home/ubuntu/hadoop-2.8.5/data
dfs_replication=1
#dependence
java_home=/usr/local/jdk1.8.0_211


[scala]
# add hosts ssh's information,use , split
hosts=172.16.244.8,172.16.244.7,172.16.244.10
localuser=ubuntu
localuser_passwd=Dwf12345
# add path for scala
scala_local_file=Tools\scala-2.12.8.tgz
scala_folder=scala-2.12.8
# If you need install scala for global,then add the following information.
# otherwise, don't care.
sudouser=ubuntu
sudouser_passwd=Dwf12345


[spark]
#-------------------------
# user,host for spark,use ',' to to separate
hosts=172.16.244.64,172.16.244.65,172.16.244.66
localuser=sparkonyarn
localuser_passwd=sparkonyarn
#sudouser
sudouser=ubuntu
sudouser_passwd=Dwf12345
#file,folder,path
local_file=Tools\spark-2.4.0-bin-hadoop2.7.tgz
software_folder=spark-2.4.0-bin-hadoop2.7
install_path=/home/sparkonyarn
#-------------------------
#config for hadoop
master_ip=172.16.244.64
master_public_ip=172.16.244.64
slaves=172.16.244.64,172.16.244.65,172.16.244.66
spark_worker_dir=/home/sparkonyarn/spark_work_240
#dependence
java_home=/home/sparkonyarn/jdk1.8.0_211
#    Can be empty,to set LD_LIBRARY_PATH
hadoop_home=/home/sparkonyarn/hadoop-2.8.5


[cassandra]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\apache-cassandra-3.0.18-bin.tar.gz
software_folder=apache-cassandra-3.0.18
install_path=/
#-------------------------
#config
#    use ',' to to separate data_directory
data_directory=/data/cassandra/data
#Method of listening,"listen_address" or "listen_interface",if "listen_interface" Then must specify "interface_name"
listening_Method=listen_address
listening_interface_name=
#Method of rpc,"rpc_address" or "rpc_interface",if "rpc_interface" Then must specify "rpc_interface_name"
rpc_Method=rpc_address
rpc_interface_name=


[zookeeper]
#-------------------------
# user,host for zookeeper,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\zookeeper-3.4.13.tar.gz
software_folder=zookeeper-3.4.13
install_path=/usr/local
#-------------------------
#config for zookeeper
dataDir=/usr/local/zookeeper_data
dataLogDir=/usr/local/zookeeper_log


[kafka]
#-------------------------
# user,host for kafka,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\kafka_2.12-2.3.0.tgz
software_folder=kafka_2.12-2.3.0
install_path=/usr/local
#-------------------------
#config for kafka
#use ',' to to separate "log_dirs" and "zookeeper_hosts"
log_dirs=/usr/local/kafka_log
zookeeper_hosts=192.168.130.171,192.168.130.172,192.168.130.173


[flink]
#-------------------------
# user,host for kafka,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\flink-1.7.2-bin-hadoop27-scala_2.11.tgz
software_folder=flink-1.7.2
install_path=/usr/local
#-------------------------
#config for flink
master_ip=192.168.130.171
slaves_ip=192.168.130.171,192.168.130.172,192.168.130.173
java_home=/usr/local/jdk1.8.0_211


[storm]
# user,host for storm,use ',' to to separate
hosts=192.168.130.4,192.168.130.5,192.168.130.6
localuser=zzm
localuser_passwd=123456
#sudouser for storm
sudouser=zzm
sudouser_passwd=123456
#file for storm
storm_local_file=Tools\apache-storm-1.2.3.tar.gz
storm_folder=apache-storm-1.2.3
#config for storm,use ',' to separate nimbus_seeds and zookeeper_hosts
zookeeper_hosts=192.168.130.5
nimbus_host=192.168.130.4
nimbus_seeds=192.168.130.4,192.168.130.5,192.168.130.6
#    if storm_data without permission,must set sudouser
storm_data=/data/storm_data
#    number of supervisor.slots.ports,default is 4
supervisor_slots_ports_num=4


[pg]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.36,192.168.130.38,192.168.130.39
localuser=zzm
localuser_passwd=123456
#sudouser
sudouser=root
sudouser_passwd=root106A
#file,folder,path
local_file=Tools\postgresql-10.15-1-linux-x64-binaries.tar.gz
software_folder=pgsql
install_path=/data/zzm/db/timescaledb
#-------------------------
#config for pg
data_path=/data/zzm/db/timescaledb/pgdata
max_connections=1000
superuser=postgres
superuser_passwd=123456


[test]
hosts=172.16.0.6
# -----
localuser=ubuntu
localuser_passwd=Dwf12345
# -----
sudouser=ubuntu
sudouser_passwd=Dwf12345
# ----
zookeeper_local_file=Tools\zookeeper-3.4.13.tar.gz
zookeeper_folder=zookeeper-3.4.13

[template]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.170
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\postgresql-10.10-2-linux-x64-binaries.tar.gz
software_folder=pgsql
install_path=/home/ubuntu
#-------------------------
#config


[deploy_cloudwise]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.7,192.168.130.11,192.168.130.12,192.168.130.13,192.168.130.14,192.168.130.15,192.168.130.17,192.168.130.18,192.168.130.19,192.168.130.20,192.168.130.21
localuser=root
localuser_passwd=root106A
#sudouser
sudouser=root
sudouser_passwd=root106A
#file,folder,path
local_file=Tools\OSAgent_Linux_2.1.2.zip
software_folder=OSAgent_Linux_2.1.2
install_path=/var/cloudwise
#-------------------------
#config
licensekey=J45Engw88NeHUZ4Q7qNsK8L47FTH**QvgW113IEnsNaBNMR5zZ**oj/g!!!!
received_hosts=http://101.6.15.214:15081


[adduser]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021
new_user=cluster
new_user_passwd=iotdb2021

[change_hostname]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021

[mount_disk]
hosts=172.16.2.3
sudouser=root
sudouser_passwd=IoTDB2021

[change_yum]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021

[zabbix_agent]
hosts=172.16.2.2,172.16.2.3,172.16.2.4,172.16.2.5,172.16.2.6,172.16.2.7,172.16.2.8,172.16.2.9,172.16.2.10,172.16.2.11,172.16.2.12,172.16.2.13,172.16.2.14,172.16.2.15,172.16.2.16,172.16.2.17,172.16.2.18,172.16.2.19,172.16.2.20,172.16.2.21,172.16.2.22,172.16.2.23,172.16.2.24,172.16.2.25,172.16.2.26,172.16.2.27,172.16.2.28,172.16.2.29,172.16.2.30,172.16.2.31,172.16.2.32,172.16.2.33
sudouser=root
sudouser_passwd=IoTDB2021

#Not supported below
[elasticsearch]
warning=!!must modify Config\elasticsearch.yml,add discovery.zen.ping.unicast.hosts is equal the env.hosts
elasticsearch_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\elasticsearch-6.6.1.tar.gz
elasticsearch_folder=elasticsearch-6.6.1
elasticsearch_data=/data/elasticsearch/data
elasticsearch_log=/data/elasticsearch/logs
[hbase]
hbase_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\hbase-2.1.3-bin.tar.gz
hbase_folder=hbase-2.1.3
hbase_rootdir=hdfs://172.16.244.5:9000/hbase
zoo_data=/data/zookeeper-data
zoo_user=ubuntu
zoo_user_pwd=Dwf12345
zoo_host=172.16.244.9
zoo_cfg_path=/home/ubuntu/zookeeper-3.4.13/conf/zoo.cfg
zookeeper_ip=172.16.244.9,172.16.244.14,172.16.244.13
[hive]
hive_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\apache-hive-2.3.4-bin.tar.gz
hive_host=172.16.244.27
hive_user=ubuntu
hive_folder=apache-hive-2.3.4-bin
mysql_connector_java_path=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\mysql-connector-java-8.0.15.jar
mysql_host=172.16.244.27
mysql_port=3306
mysql_hive_user=hive
mysql_root_pwd=123456
mysql_hive_user_pwd=hive
hadoop_path=/home/ubuntu/hadoop-2.7.7
hadoop_user=ubuntu
hadoop_password=Dwf12345
[hbase2]
hbase_file=C:\Users\MingMing\Desktop\apps\zzm_dwf3.0\Tools\flink-1.7.2-bin-hadoop27-scala_2.11.tgz
hbase_folder=flink-1.7.2