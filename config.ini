[common]
# yes or no
use_the_same_hostname=no
#
hosts=192.168.10.62,192.168.10.64
localuser=zzm
localuser_passwd=123456
sudouser=ubuntu
sudouser_passwd=123456


[jdk]
#-------------------------
# add hosts ssh info, use , split
hosts=172.20.31.15,172.20.31.16,172.20.31.17,172.20.31.18,172.20.31.24
localuser=ubuntu
localuser_passwd=Dwf12345
#sudouser
sudouser=root
sudouser_passwd=Dwf12345
#file,folder,path
local_file=Tools/jdk-11.0.18_linux-x64_bin.tar.gz
software_folder=jdk-11.0.18
install_path=/usr/local
#-------------------------
# install for alone(null) or public?
install_for=public


[iotdb-cluster]
#-------------------------
# host,user
# add hosts ssh's info, use ',' split
hosts=172.20.31.75,172.20.31.76,172.20.31.77
localuser=tes
localuser_passwd=123
#sudouser
sudouser=root
sudouser_passwd=Dwf12345
# file,folder,path
local_file=Tools/apache-iotdb-1.2.0-SNAPSHOT-all-bin.zip
software_folder=apache-iotdb-1.2.0-SNAPSHOT-all-bin
install_path=/home/tes/iotdb
# cluster info
first_confignode=172.20.31.75
config_node=172.20.31.75,172.20.31.76,172.20.31.77
data_node=172.20.31.75,172.20.31.76,172.20.31.77
[iotdb-common-config]  # iotdb-common.properties
;config_node_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;schema_replication_factor=1
;schema_region_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;data_replication_factor=1
;data_region_consensus_protocol_class=org.apache.iotdb.consensus.ratis.RatisConsensus
;schema_region_ratis_snapshot_trigger_threshold=1000
[iotdb-confignode-config]  # iotdb-confignode.properties
[iotdb-datanode-config]  # iotdb-datanode.properties





[keyfree_login]
hosts=11.101.17.130,11.101.17.131,11.101.17.132,11.101.17.133,11.101.17.134,11.101.17.135,11.101.17.136
localuser=atmos
localuser_passwd=iotdb2019


[auto_mount]
hosts=11.101.17.120,11.101.17.130,11.101.17.140
user=root
user_passwd=root106A
# eg: /dev/sdb, use , to split
mount_dev=/dev/sdb
mount_to_path=/data


[exec_order]
hosts=11.101.17.110,11.101.17.111,11.101.17.112,11.101.17.113,11.101.17.114,11.101.17.115,11.101.17.116
user=atmos
user_passwd=iotdb2019
sudouser=root
sudouser_passwd=root106A


[hostname_to_host]
hosts=192.168.130.171,192.168.130.144,192.168.130.145
#
sudouser=ubuntu
sudouser_passwd=123456
#ip and hostname must one-to-one
ip=192.168.130.171,192.168.130.144,192.168.130.145
hostname=slave1,slave2,slave3


[maven]
# add hosts ssh's information,use,split
hosts=11.101.17.121
localuser=root
localuser_passwd=root106A
# If you need install jdk for global,then add the following information.
# otherwise, don't care.
sudouser=root
sudouser_passwd=root106A
# add path for
user_home=/root
mvn_local_file=Tools\apache-maven-3.8.7-bin.tar.gz
mvn_folder=apache-maven-3.8.7


[hadoop]
#-------------------------
# user,host for hadoop,use ',' to to separate
hosts=192.168.130.171,192.168.130.144,192.168.130.145
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\hadoop-2.8.5.tar.gz
software_folder=hadoop-2.8.5
install_path=/home/ubuntu
#-------------------------
#config for hadoop
master_ip=192.168.130.171
slaves=192.168.130.171,192.168.130.144,192.168.130.145
#    data_folder can have multiple directory,use ',' to to separate data_folder and slaves
data_folder=/home/ubuntu/hadoop-2.8.5/data
dfs_replication=1
#dependence
java_home=/usr/local/jdk1.8.0_211


[scala]
# add hosts ssh's information,use , split
hosts=172.16.244.8,172.16.244.7,172.16.244.10
localuser=ubuntu
localuser_passwd=Dwf12345
# add path for scala
scala_local_file=Tools\scala-2.12.8.tgz
scala_folder=scala-2.12.8
# If you need install scala for global,then add the following information.
# otherwise, don't care.
sudouser=ubuntu
sudouser_passwd=Dwf12345


[spark]
#-------------------------
# user,host for spark,use ',' to to separate
hosts=172.16.244.64,172.16.244.65,172.16.244.66
localuser=sparkonyarn
localuser_passwd=sparkonyarn
#sudouser
sudouser=ubuntu
sudouser_passwd=Dwf12345
#file,folder,path
local_file=Tools\spark-2.4.0-bin-hadoop2.7.tgz
software_folder=spark-2.4.0-bin-hadoop2.7
install_path=/home/sparkonyarn
#-------------------------
#config for hadoop
master_ip=172.16.244.64
master_public_ip=172.16.244.64
slaves=172.16.244.64,172.16.244.65,172.16.244.66
spark_worker_dir=/home/sparkonyarn/spark_work_240
#dependence
java_home=/home/sparkonyarn/jdk1.8.0_211
#    Can be empty,to set LD_LIBRARY_PATH
hadoop_home=/home/sparkonyarn/hadoop-2.8.5


[cassandra]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\apache-cassandra-3.0.18-bin.tar.gz
software_folder=apache-cassandra-3.0.18
install_path=/
#-------------------------
#config
#    use ',' to to separate data_directory
data_directory=/data/cassandra/data
#Method of listening,"listen_address" or "listen_interface",if "listen_interface" Then must specify "interface_name"
listening_Method=listen_address
listening_interface_name=
#Method of rpc,"rpc_address" or "rpc_interface",if "rpc_interface" Then must specify "rpc_interface_name"
rpc_Method=rpc_address
rpc_interface_name=


[zookeeper]
#-------------------------
# user,host for zookeeper,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\zookeeper-3.4.13.tar.gz
software_folder=zookeeper-3.4.13
install_path=/usr/local
#-------------------------
#config for zookeeper
dataDir=/usr/local/zookeeper_data
dataLogDir=/usr/local/zookeeper_log


[kafka]
#-------------------------
# user,host for kafka,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\kafka_2.12-2.3.0.tgz
software_folder=kafka_2.12-2.3.0
install_path=/usr/local
#-------------------------
#config for kafka
#use ',' to to separate "log_dirs" and "zookeeper_hosts"
log_dirs=/usr/local/kafka_log
zookeeper_hosts=192.168.130.171,192.168.130.172,192.168.130.173


[flink]
#-------------------------
# user,host for kafka,use ',' to to separate
hosts=192.168.130.171,192.168.130.172,192.168.130.173
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\flink-1.7.2-bin-hadoop27-scala_2.11.tgz
software_folder=flink-1.7.2
install_path=/usr/local
#-------------------------
#config for flink
master_ip=192.168.130.171
slaves_ip=192.168.130.171,192.168.130.172,192.168.130.173
java_home=/usr/local/jdk1.8.0_211


[pg]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.36,192.168.130.38,192.168.130.39
localuser=zzm
localuser_passwd=123456
#sudouser
sudouser=root
sudouser_passwd=root106A
#file,folder,path
local_file=Tools\postgresql-10.15-1-linux-x64-binaries.tar.gz
software_folder=pgsql
install_path=/data/zzm/db/timescaledb
#-------------------------
#config for pg
data_path=/data/zzm/db/timescaledb/pgdata
max_connections=1000
superuser=postgres
superuser_passwd=123456


[test]
hosts=172.16.0.6
# -----
localuser=ubuntu
localuser_passwd=Dwf12345
# -----
sudouser=ubuntu
sudouser_passwd=Dwf12345
# ----
zookeeper_local_file=Tools\zookeeper-3.4.13.tar.gz
zookeeper_folder=zookeeper-3.4.13


[template]
#-------------------------
# user,host for pg ,use ',' to to separate
hosts=192.168.130.170
localuser=ubuntu
localuser_passwd=123456
#sudouser
sudouser=ubuntu
sudouser_passwd=123456
#file,folder,path
local_file=Tools\postgresql-10.10-2-linux-x64-binaries.tar.gz
software_folder=pgsql
install_path=/home/ubuntu
#-------------------------
#config


[adduser]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021
new_user=cluster
new_user_passwd=iotdb2021


[change_hostname]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021


[change_yum]
hosts=172.16.2.2
sudouser=root
sudouser_passwd=IoTDB2021


[zabbix_agent]
hosts=11.101.17.221,11.101.17.222,11.101.17.223,11.101.17.224,11.101.17.225,11.101.17.226,11.101.17.227,11.101.17.228
sudouser=root
sudouser_passwd=root106A
zabbix_server=111.202.73.232
package_url=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/5.4/rhel/7/x86_64/zabbix-agent2-5.4.12-1.el7.x86_64.rpm

